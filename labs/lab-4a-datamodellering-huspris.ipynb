{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huspris\n",
    "\n",
    "Her har vi data som beskriver boligpriser i Ames, Iowa fra 2006 til 2010. Datasettet inneholder mange variabler som kan brukes til å vurdere boligverdi. Se [her](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview) for mer informasjon om data. I denne oppgaven ser vi kun på de numeriske data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les inn husprisdata\n",
    "df = pd.read_csv('data/huspris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del data i mål-, og prediktorvariabler\n",
    "reduced_df = df.select_dtypes(include=[np.number]).drop('Id', axis=1).dropna()\n",
    "X = reduced_df.drop('SalePrice', axis=1).values\n",
    "y = reduced_df['SalePrice'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del data i trenings-, validerigns-, og testdata med størrelser 70%, 15%, 15% av data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dele data i trenings, validerings og testdata\n",
    "# generer X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "# vi gjør at 70% blir treningsdata\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_val, y_val, test_size=0.5\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tren en Grunnlinjemodell på treningsdata og finn validerings-RMSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline = DummyRegressor(strategy=\"mean\")\n",
    "baseline.fit(X_test, y_test)\n",
    "baseline\n",
    "\n",
    "# mse error given the prdicted line, what is distance from the line to actual point, squared and then the mean of all of these\n",
    "y_predicted = baseline.predict(X_val) #given a new data set x, predict the y values\n",
    "rmse_baseline = np.round(np.sqrt(mean_squared_error(y_val, y_predicted, squared=False))) #for each predicted y, check distance from known y\n",
    "rmse_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tren en Lasso regresjonsmodell (sklearn.linear_model.Lasso) med hyperparameter alpha mellom 1 og 500 på treningsdata. Sorter de ulike modellene etter mean kvadrert feil på valideringsdata (sklearn.metrics.mean_squared_error).\n",
    "Visualiser hvordan mean kvadratisk feil avhenger av alpha. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tren forskjellige modeller\n",
    "\n",
    "alpha_values = []\n",
    "mse_values = []\n",
    "\n",
    "for alpha in np.arange(1, 500, 10):\n",
    "\n",
    "    clf = Lasso(alpha=alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_predicted = clf.predict(X_val)\n",
    "    \n",
    "    # sjekk MSE for valideringsdata\n",
    "    mse = mean_squared_error(y_val, y_predicted, squared=True)\n",
    "\n",
    "    alpha_values.append(alpha)\n",
    "    mse_values.append(mse)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# visualiser validerings-MSE avhengig av alpha\n",
    "\n",
    "plt.plot(alpha_values,mse_values)\n",
    "plt.xlabel(\"alpha_values\")\n",
    "plt.ylabel(\"mse_values\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization comment\n",
    "Here one can see that as alpha goes towards ca 300 MSE decreases, and increases after ca 375. In this case, a alpha value of ~325 is best as the average MSE is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lag alle polynomkombinasjoner av grad 2 av data (sklearn.preprocessing.PolynomialFeatures). \n",
    "Tren en Lasso regresjonsmodell (sklearn.linear_model.Lasso) med hyperparameter alpha mellom 500 og 1500 på polynomkombinasjoner av treningsdata.\n",
    "Sorter de ulike modellene etter mean kvadrert feil på valideringsdata (sklearn.metrics.mean_squared_error).\n",
    "Visualiser hvordan mean kvadratisk feil avhenger av alpha. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag datasett med polynomielle data\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "X_train_pf = poly.fit_transform(X_train)\n",
    "X_val_pf = poly.transform(X_val)\n",
    "X_test_pf = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tren forskjellige modeller\n",
    "\n",
    "alpha_values_poly = []\n",
    "mse_values_poly = []\n",
    "pf_models = []\n",
    "\n",
    "for alpha in np.arange(500, 1500, 50): # hadde jump = 10 men den tok sykt langt tid\n",
    "    clf = Lasso(alpha=alpha)\n",
    "    clf.fit(X_train_pf, y_train) \n",
    " \n",
    "    y_predicted = clf.predict(X_val_pf)\n",
    "    \n",
    "    #finn mse\n",
    "    pf_mse = mean_squared_error(y_val, y_predicted, squared=True)\n",
    "\n",
    "    alpha_values_poly.append(alpha)\n",
    "    mse_values_poly.append(pf_mse)\n",
    "    pf_models.append(clf)\n",
    "    \n",
    "pf_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiser validerings-MSE avhengig av alpha\n",
    "plt.plot(alpha_values_poly,mse_values_poly)\n",
    "plt.xlabel(\"alpha_values\")\n",
    "plt.ylabel(\"mse_values\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment:\n",
    "\n",
    "In this case we can see that alpha value and mse value are correlated.  It is clear that the higher the alpha value, the lower the MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se om du kan finne en bedre modell med en annen metode enn Lasso regresjon (e.g. sklearn.linear_model.ElasticNet, sklearn.ensemble.RandomForestRegressor, sklearn.svm.SVR, sklearn.gaussian_process.GaussianProcessRegressor). Finn gode hyperparametre til metoden du velger ut. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "# tren forskjellige modeller\n",
    "\n",
    "#her prøver jeg på litt fancy greie ved å kun lage settings ett sted.\n",
    "#det er kult, men kanskje litt vel overkomplisert\n",
    "\n",
    "models = [\n",
    "    {\"model_type\": Lasso, \"settings\": {\"alpha\": 1500}},\n",
    "    {\"model_type\": RandomForestRegressor, \"settings\": {\"n_estimators\":100}}, #hadde n_estimators på 1000, da funker an bra men tar sykt lang tid\n",
    "    {\"model_type\": ElasticNet, \"settings\": {\"alpha\": 1500}}, \n",
    "    {\"model_type\": SVR, \"settings\": {\"degree\":2}},\n",
    "    {\"model_type\": GaussianProcessRegressor, \"settings\": {\"alpha\": 1500}},\n",
    "]\n",
    "\n",
    "model_strings = []\n",
    "mse_values_models = []\n",
    "\n",
    "for mod in models:\n",
    "    clf = mod[\"model_type\"](**mod[\"settings\"]) #henter ut settings her\n",
    "    clf.fit(X_train_pf, y_train) \n",
    "\n",
    "    y_predicted = clf.predict(X_val_pf)\n",
    "\n",
    "    #finn mse\n",
    "    pf_mse = mean_squared_error(y_val, y_predicted, squared=True)\n",
    "\n",
    "    mse_values_models.append(pf_mse)\n",
    "    model_strings.append(str(mod[\"model_type\"].__name__))\n",
    "\n",
    "\n",
    "\n",
    "data_models = pd.DataFrame({\n",
    "    'model_name': model_strings,\n",
    "    'mse_values': mse_values_models\n",
    "})\n",
    "\n",
    "fig = px.bar(data_models, x='model_name', y='mse_values', \n",
    "             title='MSE values for different models', \n",
    "             labels={'x':'Model', 'y':'Mean Squared Error'})\n",
    "\n",
    "fig.show()\n",
    "print(data_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sjekk MSE for valideringsdata\n",
    "data_models.sort_values(by='mse_values', inplace=True)\n",
    "mse = data_models\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Velg ut den beste modellen og sjekk hvor godt den generaliserer ved å regne ut mean kvadrert feil og kvadratrooten av mean kvadrert feil på testdata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sjekk generaliseringsevne\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "best_model = RandomForestRegressor(n_estimators=100)\n",
    "best_model.fit(X_train_pf, y_train) \n",
    "\n",
    "y_test_predicted = best_model.predict(X_test_pf)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_test_predicted)\n",
    "\n",
    "test_rmse = sqrt(test_mse)\n",
    "\n",
    "print('Test MSE:', test_mse)\n",
    "print('Test RMSE:', test_rmse)\n",
    "\n",
    "test_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gi en oppsummering over hva du har gjort og hva resultatet var. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lest inn husprisdata, delt i trening,test og validation\n",
    "\n",
    "Sett litt på en grunnlinjemodell og dens RMSE\n",
    "\n",
    "trent lasso modell og sett hvordan mse endrer seg når alpha endrer seg\n",
    "\n",
    "alpha opp = mse ned\n",
    "\n",
    "trent noen flere lasso modeller og sett på validerings data mse, når vi endrer alpha\n",
    "\n",
    "så har vi trent noen flere modeller og sett hvilken som har lavest MSE og det var ```RandomForestRegressor```\n",
    "\n",
    "Så har vi sjekket ut den modellen, sett på hvor god den er på testdataen. Det viser seg at mse er  høy, så kanskje denne modellen ikke generaliser så bra. \n",
    "\n",
    "Validation MSE: 747310700, test MSE: 1381201492. Increase = 180%\n",
    "\n",
    "RMSE er grei, men sammenlignet med validation data, ser vi at MSE er litt for høy. Det er snakk om huspris data så vi forventer høye verdier, men dette er for høyt. Jeg tror at modellen er overfitted på testdata. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
